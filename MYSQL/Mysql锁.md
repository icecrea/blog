## Mysql锁

MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类

### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。
主库上备份，那么在备份期间都不能执行更新。从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

备份是否可以不加锁？
假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。
假设不加锁。如果时间顺序上是先备份账户余额表，然后用户购买，然后备份用户课程表。在备份结果里用户状态为余额没扣，多了一门课程。后续用该备份恢复数据会有问题。
**不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。**

可重复读隔离级别下可以拿到一致性视图。
官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数`–single-transaction`的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。**single-transaction 方法只适用于所有的表使用事务引擎的库。**

### 表级锁

MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

#### 表锁

表锁的语法是 `lock tables … read/write`。与 FTWRL 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

**如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表**

线程A对T加读锁，限制其它线程写T，限制本线程写T，线程A不能访问其它表。
线程A对T加写锁，限制其它线程读写T，线程A不能访问其它表。

#### MDL锁

另一类表级的锁是 MDL（metadata lock)。
MDL 不需要显式使用，在访问一个表的时候会被自动加上。
在 MySQL 5.5 版本中引入了 MDL，**当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。**

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。

**踩坑：给一个小表加个字段，导致整个库挂了。**

![img](https://icecrea-1300414836.file.myqcloud.com/mysql/mysql45/06_lock/mdl_crash_database.jpg)



如图：sessionA先启动，加MDL读锁，B也是加MDL读锁，不影响B查询。C需要MDL写锁，因为A的MDL读锁还没有释放，所以C会被阻塞。但是之后在表t上申请MDL读锁的请求也会被C阻塞（增删改查）。等于表现在不可读写了。(问题：C没有加锁成功为什么会阻塞D？应该是因为CD均在同一个锁队列中，决定谁先执行，sessionC在等待的时候就开始阻塞后来的请求了)

如果表查询语句频繁且客户端有重试，即超时起一个新session请求，库的线程很快会饱满。
**事务中的MDL锁，在语句执行开始时申请，事务提交后再释放。**

**Q：如何安全地给小表加字段？**
1.首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。
2.如果是一个热点表，请求频繁kill不过来。理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。
`ALTER TABLE tbl_name NOWAIT add column ...` `ALTER TABLE tbl_name WAIT N add column ...`

### 行锁

MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎不支持行锁。

**在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**

**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。**
如影院购票，假设有用户余额扣除票价，影院账户余额增加票价，记录日志操作。在事务中，我们就可以把容易冲突的影院账户余额增加票价安排到最后，这样影院账户余额这一行锁时间就最小，最大程度减少了事务的锁等待，提升并发度。

#### 死锁和死锁检测



![img](https://icecrea-1300414836.file.myqcloud.com/mysql/mysql45/06_lock/dead_lcok.jpg)


如图，事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。出现死锁后有两种策略：



1. 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
   在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s。当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出。设置太小又可能导致误判，简单的锁等待。
2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。默认开启。
   每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。

怎么解决由这种热点行更新导致的性能问题呢？
1.控制并发度。如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低。并发控制要放在服务端。
2.通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。

**Q：如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到，选择哪一种？**
第一种，直接执行 delete from T limit 10000;
第二种，在一个连接中循环执行 20 次 delete from T limit 500;
第三种，在 20 个连接中同时执行 delete from T limit 500。

A：第二种比较合适。第一种方式单个语句占用时间长，锁时间长，且大事务会导致主从延迟。第三种会人为造成锁冲突。



参考：
《mysql实战45讲》丁奇